# üöÄ EKS Challenge - Infraestrutura AWS com Terraform

Este projeto implementa uma infraestrutura b√°sica na AWS utilizando Terraform, provisionando uma VPC customizada e um cluster Amazon EKS funcional.

## üìã Vis√£o Geral da Solu√ß√£o

A solu√ß√£o foi desenvolvida seguindo boas pr√°ticas de Infrastructure as Code (IaC), com c√≥digo modular, reutiliz√°vel e bem documentado. A arquitetura implementada inclui:

- **VPC customizada** com CIDR configur√°vel
- **Subnets p√∫blicas e privadas** distribu√≠das em m√∫ltiplas zonas de disponibilidade
- **NAT Gateways** para permitir acesso √† internet das subnets privadas
- **Cluster EKS** com configura√ß√£o b√°sica funcional
- **Node Group gerenciado** com auto-scaling configurado
- **Security Groups** adequados para comunica√ß√£o entre componentes
- **IAM Roles e Policies** seguindo o princ√≠pio de menor privil√©gio

## üèóÔ∏è Arquitetura

![Diagrama de Arquitetura](fluxograma.png)

### Diagrama Detalhado

O diagrama acima ilustra a arquitetura completa da infraestrutura, mostrando:

- **VPC** com CIDR 10.0.0.0/16 distribu√≠da em 2 Availability Zones
- **Subnets P√∫blicas** contendo NAT Gateways (1 por AZ)
- **Subnets Privadas** contendo os EKS Nodes
- **Internet Gateway** para comunica√ß√£o com a internet
- **EKS Cluster Control Plane** gerenciado pela AWS

### Representa√ß√£o em Texto

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         AWS Region                          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    VPC (10.0.0.0/16)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Public Subnet   ‚îÇ      ‚îÇ  Public Subnet   ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   (AZ-1a)        ‚îÇ      ‚îÇ   (AZ-1b)        ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                  ‚îÇ      ‚îÇ                  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ NAT GW 1   ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ NAT GW 2   ‚îÇ  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                          ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                    ‚îÇ                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ Internet  ‚îÇ                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  Gateway  ‚îÇ                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Private Subnet   ‚îÇ      ‚îÇ Private Subnet   ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   (AZ-1a)        ‚îÇ      ‚îÇ   (AZ-1b)        ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                  ‚îÇ      ‚îÇ                  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ EKS Nodes  ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ EKS Nodes  ‚îÇ  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ (Node      ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ (Node      ‚îÇ  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  Group)    ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ  Group)    ‚îÇ  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  EKS Cluster    ‚îÇ                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ  Control Plane  ‚îÇ                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes Principais

1. **VPC (Virtual Private Cloud)**
   - CIDR: 10.0.0.0/16 (configur√°vel)
   - DNS hostnames e DNS support habilitados

2. **Subnets**
   - **P√∫blicas**: Para recursos que precisam de acesso direto √† internet (NAT Gateways)
   - **Privadas**: Para recursos que n√£o precisam de acesso direto (EKS Nodes)
   - Distribu√≠das em m√∫ltiplas zonas de disponibilidade para alta disponibilidade

3. **Internet Gateway**
   - Permite comunica√ß√£o entre a VPC e a internet

4. **NAT Gateways**
   - Um por zona de disponibilidade
   - Permite que recursos em subnets privadas acessem a internet para downloads e updates

5. **EKS Cluster**
   - Control plane gerenciado pela AWS
   - Endpoints p√∫blicos e privados habilitados
   - Logs de cluster habilitados (API, Audit, Authenticator, Controller Manager, Scheduler)

6. **EKS Node Group**
   - Inst√¢ncias EC2 gerenciadas pela AWS
   - Auto-scaling configur√°vel (min, max, desired)
   - Localizado em subnets privadas

7. **Security Groups**
   - Cluster SG: Permite tr√°fego HTTPS (443) do VPC
   - Node Group SG: Permite comunica√ß√£o entre nodes e com o cluster

8. **IAM Roles**
   - Cluster Role: Permiss√µes para o control plane do EKS
   - Node Group Role: Permiss√µes para os nodes (Worker Node Policy, CNI Policy, ECR ReadOnly)

## üìÅ Estrutura do Projeto

```
terraform_test/
‚îú‚îÄ‚îÄ main.tf                 # Configura√ß√£o principal e chamadas dos m√≥dulos
‚îú‚îÄ‚îÄ variables.tf            # Vari√°veis do projeto
‚îú‚îÄ‚îÄ outputs.tf             # Outputs do projeto
‚îú‚îÄ‚îÄ versions.tf            # Vers√µes do Terraform e providers
‚îú‚îÄ‚îÄ .gitignore            # Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ README.md             # Este arquivo
‚îî‚îÄ‚îÄ modules/
    ‚îú‚îÄ‚îÄ vpc/
    ‚îÇ   ‚îú‚îÄ‚îÄ main.tf        # Recursos da VPC
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf   # Vari√°veis do m√≥dulo VPC
    ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf     # Outputs do m√≥dulo VPC
    ‚îî‚îÄ‚îÄ eks/
        ‚îú‚îÄ‚îÄ main.tf        # Recursos do EKS
        ‚îú‚îÄ‚îÄ variables.tf   # Vari√°veis do m√≥dulo EKS
        ‚îî‚îÄ‚îÄ outputs.tf     # Outputs do m√≥dulo EKS
```

## üöÄ Como Executar

### Pr√©-requisitos

1. **AWS CLI** instalado e configurado
   ```bash
   aws --version
   aws configure
   ```

2. **Terraform** instalado (vers√£o >= 1.5.0)
   ```bash
   terraform version
   ```

3. **Credenciais AWS** configuradas com permiss√µes adequadas para criar:
   - VPC e recursos relacionados
   - EKS clusters e node groups
   - IAM roles e policies
   - Security groups
   - NAT Gateways e Elastic IPs

### Passos para Execu√ß√£o

1. **Clone o reposit√≥rio** (ou navegue at√© o diret√≥rio)
   ```bash
   cd terraform_test
   ```

2. **Inicialize o Terraform**
   ```bash
   terraform init
   ```
   Este comando baixar√° os providers necess√°rios e inicializar√° o backend.

3. **Revise o plano de execu√ß√£o**
   ```bash
   terraform plan
   ```
   Este comando mostrar√° todos os recursos que ser√£o criados, modificados ou destru√≠dos.

4. **Aplique a configura√ß√£o**
   ```bash
   terraform apply
   ```
   Digite `yes` quando solicitado para confirmar a cria√ß√£o dos recursos.

   ‚ö†Ô∏è **Aten√ß√£o**: A cria√ß√£o do cluster EKS pode levar de 10 a 20 minutos.

5. **Configure o kubectl** (ap√≥s o apply)
   ```bash
   aws eks update-kubeconfig --region us-east-1 --name eks-challenge-dev-cluster
   ```
   Ou use o output do Terraform:
   ```bash
   terraform output -raw configure_kubectl
   ```

6. **Verifique o cluster**
   ```bash
   kubectl get nodes
   kubectl get pods --all-namespaces
   ```

7. **Destrua os recursos** (quando terminar)
   ```bash
   terraform destroy
   ```
   ‚ö†Ô∏è **Importante**: Execute este comando para evitar custos desnecess√°rios na AWS.

## ‚öôÔ∏è Configura√ß√£o e Vari√°veis

### Vari√°veis Principais

As vari√°veis podem ser configuradas atrav√©s de:
- Arquivo `terraform.tfvars` (n√£o versionado)
- Vari√°veis de ambiente (`TF_VAR_*`)
- Valores padr√£o no arquivo `variables.tf`

Principais vari√°veis:

| Vari√°vel | Descri√ß√£o | Padr√£o |
|----------|-----------|--------|
| `aws_region` | Regi√£o AWS | `us-east-1` |
| `project_name` | Nome do projeto | `eks-challenge` |
| `environment` | Ambiente (dev/staging/prod) | `dev` |
| `vpc_cidr` | CIDR da VPC | `10.0.0.0/16` |
| `availability_zones` | Zonas de disponibilidade | `["us-east-1a", "us-east-1b"]` |
| `eks_cluster_version` | Vers√£o do Kubernetes | `1.28` |
| `eks_node_instance_types` | Tipos de inst√¢ncia dos nodes | `["t3.medium"]` |
| `eks_node_desired_size` | N√∫mero desejado de nodes | `2` |
| `eks_node_min_size` | N√∫mero m√≠nimo de nodes | `1` |
| `eks_node_max_size` | N√∫mero m√°ximo de nodes | `3` |

### Exemplo de terraform.tfvars

```hcl
aws_region            = "us-east-1"
project_name          = "my-eks-project"
environment           = "dev"
vpc_cidr              = "10.0.0.0/16"
availability_zones    = ["us-east-1a", "us-east-1b"]
eks_cluster_version   = "1.28"
eks_node_instance_types = ["t3.medium"]
eks_node_desired_size = 2
eks_node_min_size     = 1
eks_node_max_size     = 3
```

## üéØ Decis√µes T√©cnicas

### 1. Modulariza√ß√£o
- **Decis√£o**: Separar VPC e EKS em m√≥dulos distintos
- **Justificativa**: Facilita reutiliza√ß√£o, manuten√ß√£o e testes. Cada m√≥dulo tem responsabilidade √∫nica.

### 2. Subnets P√∫blicas e Privadas
- **Decis√£o**: Usar subnets privadas para EKS nodes e p√∫blicas para NAT Gateways
- **Justificativa**: Seguran√ßa - nodes n√£o expostos diretamente √† internet, mas com acesso outbound via NAT.

### 3. M√∫ltiplas Zonas de Disponibilidade
- **Decis√£o**: Distribuir recursos em pelo menos 2 AZs
- **Justificativa**: Alta disponibilidade e resili√™ncia a falhas.

### 4. NAT Gateway por AZ
- **Decis√£o**: Criar um NAT Gateway por zona de disponibilidade
- **Justificativa**: Alta disponibilidade e melhor performance. Em produ√ß√£o, considere custos vs. benef√≠cios.

### 5. EKS Node Group Gerenciado
- **Decis√£o**: Usar Managed Node Group ao inv√©s de Self-Managed
- **Justificativa**: Menos overhead operacional, patches autom√°ticos, melhor integra√ß√£o com AWS.

### 6. Security Groups Restritivos
- **Decis√£o**: Configurar security groups com regras m√≠nimas necess√°rias
- **Justificativa**: Seguran√ßa - princ√≠pio do menor privil√©gio.

### 7. Tags Consistentes
- **Decis√£o**: Aplicar tags em todos os recursos usando `default_tags` e tags expl√≠citas
- **Justificativa**: Facilita gest√£o de custos, compliance e organiza√ß√£o.

### 8. Logs do Cluster Habilitados
- **Decis√£o**: Habilitar logs do control plane do EKS
- **Justificativa**: Observabilidade e troubleshooting facilitados.

## üîí Backend do Terraform

### Estado Local (Atual)

O projeto est√° configurado para usar backend local (padr√£o do Terraform). O arquivo de estado (`terraform.tfstate`) √© armazenado localmente.

### Backend Remoto (Recomendado para Produ√ß√£o)

Em um ambiente real de produ√ß√£o, recomenda-se usar um backend remoto para armazenar o estado do Terraform. Isso permite:

- **Estado compartilhado**: M√∫ltiplos desenvolvedores podem trabalhar no mesmo projeto
- **Locking**: Evita conflitos quando duas pessoas tentam aplicar mudan√ßas simultaneamente
- **Backup autom√°tico**: Estado armazenado de forma segura
- **Integra√ß√£o com CI/CD**: Pipelines podem acessar o estado remotamente

#### Como seria implementado em produ√ß√£o:

**1. Criar recursos necess√°rios:**
- Bucket S3 para armazenar o estado (com versionamento e criptografia habilitados)
- Tabela DynamoDB para state locking
- Pol√≠ticas IAM para controle de acesso

**2. Configurar no Terraform:**

Adicionar no arquivo `versions.tf`:

```hcl
terraform {
  backend "s3" {
    bucket         = "terraform-state-company-project"
    key            = "eks-challenge/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-state-lock"
  }
}
```

**3. Migrar estado existente:**

```bash
terraform init  # Migra automaticamente o estado local para o S3
```

Para m√∫ltiplos ambientes, usar diferentes `key` paths (ex: `eks-challenge/dev/terraform.tfstate`, `eks-challenge/prod/terraform.tfstate`).

## üêõ Dificuldades Encontradas

1. **Configura√ß√£o de Security Groups**
   - **Desafio**: Garantir comunica√ß√£o adequada entre cluster e nodes
   - **Solu√ß√£o**: Criar security groups espec√≠ficos e configurar regras de ingress/egress apropriadas

2. **IAM Roles e Policies**
   - **Desafio**: Entender quais pol√≠ticas s√£o necess√°rias para EKS funcionar corretamente
   - **Solu√ß√£o**: Seguir documenta√ß√£o oficial da AWS e usar managed policies quando poss√≠vel

3. **Depend√™ncias entre Recursos**
   - **Desafio**: Garantir ordem correta de cria√ß√£o (VPC ‚Üí Subnets ‚Üí EKS)
   - **Solu√ß√£o**: Usar `depends_on` explicitamente e aproveitar depend√™ncias impl√≠citas do Terraform

4. **C√°lculo de CIDRs para Subnets**
   - **Desafio**: Calcular CIDRs corretamente para m√∫ltiplas subnets
   - **Solu√ß√£o**: Usar fun√ß√£o `cidrsubnet()` do Terraform para c√°lculo autom√°tico

## üìä Pontos de Melhoria Identificados

Esta se√ß√£o lista brevemente os principais pontos de melhoria que seriam implementados em um ambiente de produ√ß√£o real:

- **Seguran√ßa**: Implementar Network ACLs, restringir endpoints p√∫blicos do EKS, habilitar encryption at rest, usar AWS Secrets Manager
- **Observabilidade**: Integrar CloudWatch Container Insights, configurar Prometheus/Grafana, implementar logging centralizado e alertas
- **Escalabilidade**: Implementar Cluster Autoscaler, configurar HPA, considerar Fargate e m√∫ltiplos node groups
- **CI/CD**: Integrar pipelines automatizados, implementar GitOps, adicionar testes de infraestrutura
- **Backup e DR**: Configurar backups de EBS, implementar estrat√©gia de backup do etcd, documentar procedimentos de DR
- **Custos**: Implementar Reserved Instances, usar Spot Instances onde apropriado, otimizar custos com Cost Explorer
- **Governan√ßa**: Implementar AWS Organizations, configurar AWS Config para compliance, estabelecer pol√≠ticas de tagging

## üìö Refer√™ncias Utilizadas

- [Terraform AWS Provider Documentation](https://registry.terraform.io/providers/hashicorp/aws/latest/docs)
- [Amazon EKS User Guide](https://docs.aws.amazon.com/eks/latest/userguide/)
- [AWS VPC Best Practices](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-best-practices.html)
- [Conventional Commits](https://www.conventionalcommits.org/)
- [Terraform Best Practices](https://www.terraform.io/docs/cloud/guides/recommended-practices/index.html)

---

Sempre execute `terraform destroy` ap√≥s concluir os testes para evitar custos desnecess√°rios na AWS.

